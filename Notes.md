
## Test Data
All GENCODE Data is taken from release 28 of the human genome
https://www.gencodegenes.org/releases/current.html
**Transcript reference file**  
gencode.v28.transcripts.fa.gz ~65MB  
Downloaded from GENCODE release 28 (GRCh38.p12)  
```bash
wget "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_28/gencode.v28.annotation.gtf.gz"
```
* Note: refused connection error being encountered, currently unresolved  

**Genome reference file**  
GRCh38.primary_assembly.genome.fa.gz ~840MB  
Downloaded from GENCODE release 28 (GRCh38.p12)  
```bash
wget "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_28/GRCh38.primary_assembly.genome.fa.gz"
```
**Transcript reference file**    
gencode.v28.transcripts.fa 
Downloaded from GENCODE release 28 (GRCD38.p12)
```bash
wget "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_28/gencode.v28.transcripts.fa.gz"
```

**Paired read files**  
* fastq read files were taken from the lab directory /homes/wheelerlab2/Data/gEUVADIS_RNASeq  

## Kallisto
current version 0.44.0  
  
**references**  
https://pachterlab.github.io/kallisto/  
  
**Pros of Kallisto**  
* Incredibly fast - does not require timely indexing, mapping, and its pseudoalignment is faster than normal alignment softwares
* Highly accurate - Kallisto performs comparably well to normal alignment software such as RSEM (R^2 value of 0.95 between TPM of the same data)
* Strong accuracy estimation - Because of kallisto's high speed, it is able to perform many levels of bootstrap comparably fast allowing for more accurate estimation of transcript error.  

**Cons of Kallisto**  
* Difficulties in downstream processing - pseudoalignment.bam files generated by kallisto cannot be processed by tools such as leafcutter. This particular case is because leafcutter relies on the CIGAR string within a bamfile to identify split mapped reads. Kallisto pseudoalignment.bam files do not write the true CIGAR string, but rather a placeholder value that leafcutter will not process.   

**Conclusion & Utility**    
Kallisto is a highly fast and accurate tool for transcript quantification. However, due to the difficulty in running other downstream analysis its is recommended that it is primarily used as the final step in a pipeline. Should the study require analysis beyond that of  gene and transcript abundance, particularly of the bamfiles, it would be more appropriate to use an aligner such as STAR coupled with another abundance estimation software such as RSEM, HTSeq, or Salmon.  

**Kallisto installation**  
requires conda installed and the bioconda channel be opened

```bash
conda config --add channels conda-forge
conda config --add channels bioconda

conda install kallisto
```
* Note: permission denied error encountered, resolved by running these commands with **sudo**  
* Note: conda is not currently in the PATH. Typing out the full path to conda resolves this, but is not optimal.

**running Kallisto**  
* Initial testing was run on the using the transcript fastq file taken from the GENCODE project, see **Test Data** for download instructions
* Paired reads ERR188030_1.fastq.gz (1151 MB) and ERR188030_2.fastq.gz (1136 MB) were used to test this data

**1. Creating an index file**  
Index generation is  a single step that should be a one time process for a given reference file. Should always be performed prior to the rest of the transcriptome quantification. This is a one time process for a given reference file and should only take up to 10 minutes.
```bash
kallisto index -i name_of_index_file.idx gencode.v28.transcripts.fa.gz
```
* Runtime of this step on GENCODE data 3m38s
* Name of index file should be established here and used from this point on for .idx arguments
* Note: Kallisto and transcript file are not currently in the PATH. Typing out the full PATH to these items resolves this, but is not optimal.

**2a. Quantifying transcript abundances**
 ```bash
 kallisto quant -i name_of_index_file.idx -o output_directory -b 100 ERR188030_1.fastq.gz ERR188030_2.fastq.gz
 ## to generate the pseudoaligned bam file use the --genomebam and --gtf options. --gtf option points to a gtf annotation file
 path/to/kallisto quant -i path/to/name_of_index_file.idx --genomebam --gtf /path/to/gtf/file-o output_directory -b 100 path/to/ERR188030_1.fastq.gz path/to/ERR188030_2.fastq.gz
 ```
* Runtime with bootstrap = 100 (-b 100) 42m47s
* Runtime with bootstrap = 0 2m37s
* Runtime with bootstrap = 0 and with generation pseudobam file 16m21s
* Manual notes it is possible to increase the runtime by up to 15% but this has not been explored
* Note: read files may be in a different directory than the wd. Typing out the full PATH to these items resolves this, but is not optimal.
* Note: Uncertain if kallisto has the ability to name the output files for this step may interfere with downstream processing - may be adequate to name a unique directory for each output but not optimal  
  
**2b. Looping kallisto quantification**

```bash
./loop_kallisto /path/to/fastq/directory/
```
* Currently loop_kallisto takes 1 argument and 2 options
	* **-i** or **--inputdirectory** is a required argument  
	* should specify the path to the directory containing the sample files - should end with a /
	* **-b** or **--bootstrap** is an option
	* specify the number of bootstraps you wish to perform
	* Default it currently set to 0
	* **-s** or **-samplenumber** is an option
	* User specifies how many samples within the directory they wish to use
	* Currently oriented towards paired end samples
	* Default is 10
	* Primary use is for testing and can be easily removed as an option
* Index generation should always be performed prior to this
* Code should be updated to ask if this index has been generated yet
* Code calls the reads_per_gene_kallisto.py after each loop
* currently does not generate bamfiles - update as user option?

Speeds at different levels of bootstrap using 5 sample pairs
* @bootstrap = 0, run time = 47m30s
* @bootstrap = 10, run time = 99m11s
* @bootstrap = 100, run time = 531m41s

**2c. Quantifying gene abundance**
```bash
python3 reads_per_gene_kallisto.py /path/to/abundance.tsv /desired/output/path/out_name.tsv
```
* This bit of code is now automatically called by the loop_kallisto script and is not necessary to invoke

## STAR
version 2.6.0c   

**Running Star** 

**1. Creating an index file**  
first create a directory to place the index file
```bash
mkdir StarTest
```
Next, STAR will not accept compressed genome files as input, unzip the reference genome with zcat or gunzip -c and append it to a new file.   
```bash
gunzip -c GRCh38.primary_assembly.genome.fa.gz > GRCh38.primary_assembly.genome.fa
```
Next create the index file   
```bash 
STAR --runMode genomeGenerate --genomeDir StarTest --genomeFastaFiles Data/Gencode/GRCh38.primary_assembly.fa
```
* Note: This process takes a long time recommended that it's run with nohup or similar. To time with nohup run as follows
```bash
nohup bash -c "time STAR --runMode genomeGenerate --genomeDir StarTest --genomeFastaFiles Data/Gencode/GRCh38.primary_assembly.fa"
```
* Approximate time 112m

**2.Map the gzipped FASTQ files outputting unsorted and coordinate-sorted BAMs**  
\* This process was taken from Alternate Protocol 7 of Dobin & Gingeras (2016)  
[Mapping RNA-Seq Reads with STAR](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4631051/)
* Requires a gtf file
  * Should be possible to directly pass STAR the transcript file in place of the genome file and gtf file but this has not been tested

```bash

STAR --genomeDir ~/StarTest/ --sjdbGTFfile ~/DATA/GenCode/gencode.v28.annotation.gtf --readFilesIn "${FastqDir}""${fastq}"* --readFilesCommand zcat --quantMode TranscriptomeSAM GeneCounts --outSAMtype BAM Unsorted SortedByCoordinate

#description of options 
--genomeDir ~/StarTest/ #the directory containing the index file for the reference genome
--sjdbGTFfile ~/DATA/GenCode/gencode.v28.annotation.gtf #the path to the file with annotated transcripts in the standard GTF format. Optional, but Star notes this as highly recommended
--readFilesIn "${FastqDir}""${fastq}"* #the fasta read files to be aligned. If multiple read files should be a space separated list
--readFilesCommand zcat #should be used if your read files are compressed. In this case our fasta files are gzipped so zcat is appropriate to read them.
--quantMode TranscriptomeSAM GeneCounts #These two arguments give two alignments that may be useful in downstream processing. TranscriptomeSAM gives the Aligned.toTranscriptome.out.bam that may be used by salmon and rsem. GeneCounts gives an the ReadsPerGene.out.tab I don't know what this is for yet. Both arguments may be supplied at once for both files.
--outSAMtype BAM Unsorted SortedByCoordinate #This argument specifies 3 things. BAM tells STAR we want alignment files to be in .bam format rather than .sam ; SortedByCoordinate generates an alignment that is sorted by transcript coordinate while Unsorted provides an unsorted alignment file.

```
 * Time for this process on one individual star run is estimated to take between 30m to 1 hour +
 * Time for this process to run on 10 samples was 494m29s or about 8 hours
 * Some of these options were only included for testing and may have slowed the process down moderately. I estimate its possible to shave off about an hour at minimum with the current sample size
 ## RSEM  
 
 **3. Prepare the RSEM reference files**
 
 ```bash
 ~/RSEM/rsem-prepare-reference --gtf ~/DATA/GenCode/gencode.v28.annotations.gtf ~/DATA/GenCode/GRCh38.primary_assembly.genome.fa ~/RSEM/ref
 ```
 
* Note: STAR does perform WASP filtering - appends a tag to the end of alignments indicating whether it passed or failed.
  * Need to check if this requires WASP installation or if this feature is built in   

**4. Run RSEM quantification on the STAR transcriptomic BAM file**
```bash
~/RSEM/rsem-calculate-expression --bam --no-bam-output -p 12 --paired-end --forward-prob 0 ~/transcriptStar_out/Aligned.toTranscriptome.out.bam ~/RSEM/ref ~/transcriptStar_out/Quant >& ~/transcriptStar_out/rsem.log
```
* Approximate time 106m53.44s

## Salmon  
Current version 0.10.0
* Requires reference transcriptome and annotation files  
**Reference**  
[Salmon manual](https://media.readthedocs.org/pdf/salmon/latest/salmon.pdf)  
[Salmon webpage](https://combine-lab.github.io/salmon/)


**Pros of Salmon**
* Flexible quantification methods - capable of performing quantification using both pre aligned sequences similar to RSEM as well as performing quasi-mapping similar to kallisto ([Some would say too similar](https://liorpachter.wordpress.com/2017/08/02/how-not-to-perform-a-differential-expression-analysis-or-science/)). 
* Incredibly fast - Both methods of quantification have been shown to be considerably faster than most existing softwares aside from kallisto and other pseudoaligners to which it matches in terms of speed.  
* Works well with other softwares - Owing to its flexible quant methods it can either stand alone or work with STAR aligned files.  
* Gives both gene and transcript level quantification if specified.
**Cons of Salmon**  
* Requires multiple reference files - Needs a reference transcriptome file in order to give transcript level quantification. Built in methods to output gene level abundances also require an additional annotation.gtf file.
* Unsorted outputs - outputs do not appear to be sorted on the gene or transcript level by name or abundance
* Transcripts untagged - The transcript quantification does not tag each transcript with the name of the gene it maps too nor does the gene quantification list which transcripts mapped to it.
  
**Conclusions & utility**  
Currently it is recommended that salmon be used for its alignment based quantification method in conjunction with aligment performed with STAR. This will give quantification at a speed similar to that of kallisto as well as more flexible downstream analysis utilizing the bam files generated by STAR. Questions about salmon's theft of intellectual property are beside the point, but are hopefully circumvented by using the alignment based quantification rather than the quasi-mapping method.
  
**Installing Salmon**  
Pre-compiled binaries of Salmon can be found on the Combine lab's github under the releases top. 
```bash
wget "https://github.com/COMBINE-lab/salmon/releases/download/v0.10.0/salmon-0.10.0_linux_x86_64.tar.gz"
```
next untar the library
```bash
tar xzvf Salmon-0.8.1_linux_x86_64.tar.gz
```
Salmon is now technically installed. The executable is located within $DIR/Salmon-0.8.1_linux_x86_64/bin/
It can be added to the path or it can be called with a direct path to the executable. 
personally I recommend adding it to the path.

```bash
PATH=$PATH:/path/to/Salmon-0.8.1_linux_x86_64/bin/
```  
**Running salmon**  

Salmon has two quantification methods. One uses 'quai-mapping' a concept of alignment very similar to kallisto's pseudoalignment ([Some would say too similar](https://liorpachter.wordpress.com/2017/08/02/how-not-to-perform-a-differential-expression-analysis-or-science/)) . The second method is the one that this pipeline will focus on, the alignment based method. At this point in our pipeline it is assumed that STAR alignment to the transcriptome has already been performed on the sample reads. Salmon will use the Aligned.toTranscriptome.out.bam file generated by STAR as well as the the gencode reference files, gencode.v28.transcripts.fa and gencode.v28.annotation.gtf.  
  
```bash
salmon quant -t gencode.v28.transcripts.fa -l A -a Aligned.toTranscriptome.out.bam -o ./salmon_quant --gencode -g gencode.v28.annotation.gtf

##desc of options
-t #this option must be supplied with a refernce transcriptome
-l A #this argument has several options describing how our reads were mapped to the transcriptome. Look at salmon documentation for further explanation. If you are uncertain what to use go with A, as salmon will attempt to automatically infer this information.
-o ./salmon_quant #The desired output directory for salmon
--gencode  #specifies that the reference transcriptome is in gencode format
-g gencode.v28.annotation.gtf #this argument must be supplied with an annotation.gtf file in order to receive gene level quantification in addition to transcript level.
```
That is it. This will output two files: quant.sf, containing the transcript level abundances, and quant.genes.sf, containing gene level abundances. You may also wish to sort one or both outputs by ensemble ID. This can be done in bash as follows.
```bash
( head -n 1 quant.genes.sf && tail -n +2 quant.genes.sf | sort -k 1) > quant.genes.sorted.sf
```
Approximate runtime on one pre-aligned sample pair (not including time for alignment, or processing the the reference files):  
2m4s

## Leafcutter

[Please refer to the full documentation for further questions](http://davidaknowles.github.io/leafcutter/articles/sQTL.html)
Leafcutter will be run independent of any quantification software and will be run on STAR alignment files.   

**1. Generate the junction files**    
an individual junction file can be generated as such    
```bash
sh $LeafcutterLoc/scripts/bam2junc.sh ~/test_runs/"${fastq}_star"/Aligned.out.bam ~/test_runs/juncfiles/"${fastq}.staraligned.junc"
 #this will take the alignment file taken by an individual star run and convert it to the junction file
```
Looping it on multiple alignments is similarly simple
```bash
cat fastq_list_star.txt | while read fastq #will make sure that the star outputs are the same as the leafcutter inputs
do         
	echo Converting "${fastq}" associated Aligned.out.bam to "${fastq}.starlaligned.junc"
	sh $LeafcutterLoc/scripts/bam2junc.sh ~/test_runs/"${fastq}_star"/Aligned.out.bam ~/test_runs/juncfiles/"${fastq}.staraligned.junc"
	echo "${fastq}.staraligned.junc" >> ~/test_runs/juncfiles/juncfiles.txt
done
```
Note that this method relies on the .txt file generated in a previous step - keep track of where this file is located    

**2.Mapping of intron clusters** 

```bash
python "${LeafcutterLoc}"/clustering/leafcutter_cluster.py -j ~/test_runs/juncfiles/juncfiles.txt -m 50 -o "${out}" -l 500000
```

**3a. Filtering unmapped loci**
```bash
zcat "${out}_perind.counts.gz" | grep "chr" > "${out}"_filtered_perind.counts.gz #filtering step - removes unmapped loci that woukld break leafcutter
```
**3b. Calculate the intron excision ratios**
```bash
python "${LeafcutterLoc}"/scripts/prepare_phenotype_table.py ~/test_runs/juncfiles/"${out}"_filtered_perind.counts.gz -p 10
```
* Approximate runtime on 10 samples 56m32s (?)

## Samtools


samtools view $BAMFILE | head

## Bash Scripting Tips & Tricks     

**setting default arguments for options**

```bash
LINES=50       # Default number of lines saved.

if [ -n "$1" ]
# Test whether command-line argument is present (non-empty).
then
  lines=$1
else  
  lines=$LINES # Default, if not specified on command-line.
fi  
```

**Double quote your variables**
```bash
"${var}"
```
Prevents misinterpretation of special characters and values containing spaces

**$ argument interpolation**     

```bash
echo "Last program's return value: $?"
echo "Script's PID: $$"
echo "Number of arguments passed to script: $#"
echo "All arguments passed to script: $@"
echo "Script's arguments separated into different variables: $1 $2..."
```

**check the number of arguments is correct**    
```bash
E_WRONG_ARGS=85
script_parameters="-a -h -m -z"
#                  -a = all, -h = help, etc.

if [ $# -ne $Number_of_expected_args ]
then
  echo "Usage: `basename $0` $script_parameters"
  # `basename $0` is the script's filename.
  exit $E_WRONG_ARGS
fi
```
**reading user input**
```bash
read variable_name #Read one line from the standard input, (or from a file) and assign the word(s) to variable name(s).
```

**Parsing arguments with flags**
```bash
#!/bin/sh
# Keeping options in alphabetical order makes it easy to add more.

while :
do
    case "$1" in
      -f | --file)
	  file="$2"   # You may want to check validity of $2
	  shift 2
	  ;;
      -h | --help)
	  display_help  # Call your function
	  # no shifting needed here, we're done.
	  exit 0
	  ;;
      -u | --user)
	  username="$2" # You may want to check validity of $2
	  shift 2
	  ;;
      -v | --verbose)
          #  It's better to assign a string, than a number like "verbose=1"
	  #  because if you're debugging the script with "bash -x" code like this:
	  #
	  #    if [ "$verbose" ] ...
	  #
	  #  You will see:
	  #
	  #    if [ "verbose" ] ...
	  #
          #  Instead of cryptic
	  #
	  #    if [ "1" ] ...
	  #
	  verbose="verbose"
	  shift
	  ;;
      --) # End of all options
	  shift
	  break;
      -*)
	  echo "Error: Unknown option: $1" >&2
	  exit 1
	  ;;
      *)  # No more options
	  break
	  ;;
    esac
done
```


## Useful commands

bash commands
```bash

PATH=$PATH:/path/to/whatever/directory #temporarily adds to path whatever directory is specified. Lasts as long as the current session

( head -n $x infile && tail -n +$(x+1) infile | sort -k $y ) > out_file #sort a file with a header by column. Skip the first $x lines, and sort by the $yth column (assume start at 1 counting)

/usr/local/bin/anaconda3/bin/python3 #path to python3 on wheeler lab

chmod a+x script_name #mak ea custom script executable

wget "some_url_here" #retrieve data from a url

nohup your_commands_here --whatever --arguments #continues to run the process even if you leave the server

nohup taskset -c some_number your_command_here #runs your command on a specific core Note wheeler lab has 12 (0-11) cores

some_command & #runs command in the background

bash -c "Command_as_string" #interprets the string input as bash command with spaces delimiting positional arguments"

time Some_command #times how long it takes to execute Note does not work with nohup unless used in conjunction with bash -c

top #displays what processes are running typing 1 will display core use

kill -9 PID #kill a process using its pid number
kill -9 $(pgrep -f command_name) #useful for commands that execute loops - exits the whole loop not just one iteration

`ps aux --sort=-%mem | head` #To see which processes are using the most memory:

#To free up memory, run these commands:
sync
su
echo 3 > /proc/sys/vm/drop_caches

//useful combination
nohup taskset -c # bash -c "time Some_Command --argument &" //runs your job in the background on a specified core, times it , and doesn't terminate when you leave the shell
```
